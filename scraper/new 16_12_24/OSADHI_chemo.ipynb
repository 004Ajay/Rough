{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Plant's Scientific Name and Link to their details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://neist.res.in/osadhi/chemo.php\"\n",
    "# get headers from \"https://www.whatismybrowser.com/\"\n",
    "HEADERS = ({'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = requests.get(url, headers=HEADERS)\n",
    "soup = BeautifulSoup(webpage.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_name_lst = soup.find_all(\"a\", href=True)\n",
    "chemo_name_lst = chemo_name_lst[12:-9] # slice out unwanted items from the list\n",
    "chemo_name_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chemo_name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_names_chemo_dict = {'Phytochemical': [], 'Link': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chemo_name in chemo_name_lst:\n",
    "    try:\n",
    "        chem_names_chemo_dict['Phytochemical'].append(chemo_name.text.strip()) # add scientific name of the plant to dict \n",
    "        element = chemo_name.find(\"a\", href=True)\n",
    "        final_link = str(\"https://neist.res.in/osadhi/\" + chemo_name['href'])\n",
    "        chem_names_chemo_dict['Link'].append(final_link) # add link of the corresponding plant to dict \n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_names_chemo_df = pd.DataFrame(chem_names_chemo_dict)\n",
    "chem_names_chemo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_names_chemo_df.to_csv(\"OSADHI_Chemo_ChemName_Links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping each plant's specific details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_man = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\"><head>\n",
    "<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
    "  <meta charset=\"utf-8\">\n",
    "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\">\n",
    "\n",
    "  <title>OSADHI</title>\n",
    "  <meta content=\"\" name=\"description\">\n",
    "  <meta content=\"\" name=\"keywords\">\n",
    "\n",
    "  <!-- Favicons -->\n",
    "  <link href=\"https://neist.res.in/osadhi/assets/img/favicon.png\" rel=\"icon\">\n",
    "  <link href=\"https://neist.res.in/osadhi/assets/img/apple-touch-icon.png\" rel=\"apple-touch-icon\">\n",
    "\n",
    "  <!-- Google Fonts -->\n",
    "  <link href=\"OSADHInothing_files/css.css\" rel=\"stylesheet\">\n",
    "\n",
    "  <!-- Vendor CSS Files -->\n",
    "  <link href=\"OSADHInothing_files/aos.css\" rel=\"stylesheet\">\n",
    "  <link href=\"OSADHInothing_files/bootstrap.min_002.css\" rel=\"stylesheet\">\n",
    "  <link href=\"OSADHInothing_files/bootstrap-icons.css\" rel=\"stylesheet\">\n",
    "  <link href=\"OSADHInothing_files/glightbox.min.css\" rel=\"stylesheet\">\n",
    "  <link href=\"OSADHInothing_files/swiper-bundle.min.css\" rel=\"stylesheet\">\n",
    "\n",
    "  <!-- Template Main CSS File -->\n",
    "  <link href=\"OSADHInothing_files/style.css\" rel=\"stylesheet\">\n",
    "  \n",
    "  <!-- Plugins for DataTable-->\n",
    "  <link href=\"OSADHInothing_files/jquery.dataTables.min.css\" rel=\"stylesheet\">\n",
    "  <link href=\"OSADHInothing_files/buttons.dataTables.min.css\" rel=\"stylesheet\">\n",
    "\n",
    "  <!-- =======================================================\n",
    "  * Template Name: eStartup - v4.7.1\n",
    "  * Template URL: https://bootstrapmade.com/estartup-bootstrap-landing-page-template/\n",
    "  * Author: BootstrapMade.com\n",
    "  * License: https://bootstrapmade.com/license/\n",
    "  ======================================================== -->\n",
    "\n",
    "    <link href=\"OSADHInothing_files/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <link href=\"OSADHInothing_files/style_002.css\" rel=\"stylesheet\">\n",
    "\n",
    "  <link rel=\"stylesheet\" href=\"OSADHInothing_files/bootstrap.min_003.css\">\n",
    "  <script src=\"OSADHInothing_files/jquery.min.js\"></script>\n",
    "  <script src=\"OSADHInothing_files/bootstrap.min.js\"></script>\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"OSADHInothing_files/font-awesome.min.css\">\n",
    "<style>\n",
    "body {\n",
    "  margin: 0;\n",
    "  font-family: Arial, Helvetica, sans-serif;\n",
    "}\n",
    "\n",
    ".topnav {\n",
    "  overflow: hidden;\n",
    "  background-color: #333;\n",
    "}\n",
    "\n",
    ".topnav a {\n",
    "  float: left;\n",
    "  display: block;\n",
    "  color: #f2f2f2;\n",
    "  text-align: center;\n",
    "  padding: 14px 16px;\n",
    "  text-decoration: none;\n",
    "  font-size: 17px;\n",
    "}\n",
    "\n",
    ".topnav a:hover {\n",
    "  background-color: #ddd;\n",
    "  color: black;\n",
    "}\n",
    "\n",
    ".topnav a.active {\n",
    "  background-color: #4CAF50;\n",
    "  color: white;\n",
    "}\n",
    "\n",
    ".topnav .icon {\n",
    "  display: none;\n",
    "}\n",
    "\n",
    "@media screen and (max-width: 600px) {\n",
    "  .topnav a:not(:first-child) {display: none;}\n",
    "  .topnav a.icon {\n",
    "    float: right;\n",
    "    display: block;\n",
    "  }\n",
    "}\n",
    "\n",
    "@media screen and (max-width: 600px) {\n",
    "  .topnav.responsive {position: relative;}\n",
    "  .topnav.responsive .icon {\n",
    "    position: absolute;\n",
    "    right: 0;\n",
    "    top: 0;\n",
    "  }\n",
    "  .topnav.responsive a {\n",
    "    float: none;\n",
    "    display: block;\n",
    "    text-align: left;\n",
    "  }\n",
    "}\n",
    "</style>\n",
    "\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "  <!-- ======= Header ======= -->\n",
    "  <header id=\"header\" class=\"header fixed-top d-flex align-items-center\">\n",
    "    <div class=\"container d-flex align-items-center justify-content-between\">\n",
    "\n",
    "      <div id=\"logo\">\n",
    "        <h1><a href=\"https://neist.res.in/osadhi/index.html\"><span>OSADHI </span>- Online Structural and Analytics based Database for Herbs of India</a></h1>\n",
    "        <!-- Uncomment below if you prefer to use an image logo -->\n",
    "        <!-- <a href=\"index.html\"><img src=\"assets/img/logo.png\" alt=\"\" title=\"\" /></a>-->\n",
    "      </div>\n",
    "\n",
    "      <nav id=\"navbar\" class=\"navbar\">\n",
    "        <ul>\n",
    "          <li><a class=\"nav-link scrollto active\" href=\"https://neist.res.in/osadhi/index.html\">Home</a></li>\n",
    "\n",
    "          <li><a class=\"nav-link scrollto\" href=\"https://neist.res.in/osadhi/index.html#about-us\">About</a></li>\n",
    "          <li><a class=\"nav-link scrollto\" href=\"https://neist.res.in/osadhi/index.html#features\">Features</a></li>\n",
    "\n",
    "\t\t  <li class=\"dropdown\"><a href=\"#\"><span>Search</span> <i class=\"bi bi-chevron-down\"></i></a>\n",
    "            <ul>\n",
    "              <li><a href=\"https://neist.res.in/osadhi/nsearch.php\">Name</a></li>\n",
    "              <li><a href=\"https://neist.res.in/osadhi/tsearch.php\">Therapeutics</a></li>\n",
    "              <li><a href=\"https://neist.res.in/osadhi/fsearch.php\">Family</a></li>\n",
    "              <li><a href=\"https://neist.res.in/osadhi/psearch.php\">Phytochemicals</a></li>\n",
    "              <li><a href=\"https://neist.res.in/osadhi/npsearch.php\">Natural Product Classes</a></li>\n",
    "<!--\n",
    "\t\t\t  <li class=\"dropdown\"><a href=\"#\"><span>Natural Product Classes</span> <i class=\"bi bi-chevron-right\"></i></a>\n",
    "                <ul>\n",
    "                  <li><a href=\"#\">Alkaloids</a></li>\n",
    "                  <li><a href=\"#\">Terpenoids</a></li>\n",
    "                  <li><a href=\"#\">Flavanoids</a></li>\n",
    "                </ul>\n",
    "              </li>\n",
    " -->\n",
    "            </ul>\n",
    "          </li>\n",
    "          <li><a class=\"nav-link scrollto\" href=\"https://neist.res.in/osadhi/index.html#team\">Team</a></li>\n",
    "          <li><a class=\"nav-link scrollto\" href=\"https://neist.res.in/osadhi/index.html#contact\">Contact</a></li>\n",
    "        </ul>\n",
    "        <i class=\"bi bi-list mobile-nav-toggle\"></i>\n",
    "      </nav><!-- .navbar -->\n",
    "    </div>\n",
    "  </header><!-- End Header -->\n",
    "\n",
    "  <main id=\"main\">\n",
    "\n",
    "    <!-- ======= Breadcrumbs ======= -->\n",
    "    <section class=\"breadcrumbs\">\n",
    "      <div class=\"container\">\n",
    "\n",
    "        <div class=\"d-flex justify-content-between align-items-center\">\n",
    "<!--\n",
    "          <h2>Inner Page</h2>\n",
    "          <ol>\n",
    "            <li><a href=\"index.html\">Home</a></li>\n",
    "            <li>Inner Page</li>\n",
    "          </ol>\n",
    "-->\n",
    "\n",
    "\n",
    "<div class=\"container\">\n",
    "\t<div class=\"row\">\n",
    "\t<div class=\"container well\">\n",
    "<!--\n",
    "\t\t<div class=\"col-md-4\">\n",
    "\n",
    "\t\t<h2 class=\"text-center\">List of plants having phytochemicals:   (1S,8'R)-6-methoxy-2-methylspiro[3,4-dihydroisoquinoline-1,7'-6,8-dihydrocyclopenta[g][1,3]benzodioxole]-7,8'-diol</h2>\n",
    "\t\t<center><hr style=\"height:3px;border-width:0;color:black;background-color:gray\"></center><br>\n",
    "\t\t<div style=\"height: 600px; overflow-y: auto;\">\n",
    "\t\t\t<table id=\"example5\" class=\"table table-striped table-bordered\">\n",
    "\t        \t<thead>\n",
    "\t                <tr>\n",
    "\t                    <th>Sl. No</th>\n",
    "\t                    <th>Plant Name</th>\n",
    "\t              \t</tr>\n",
    "\t          \t</thead>\n",
    "\t        \t<tbody>\n",
    "\t\t\t\t\n",
    "\t        \t\t--></div></div></div></div></div></section></main></body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://neist.res.in/osadhi/chemodetail.php?phyto=%0Adicerandrol+C\"\n",
    "webpage2 = requests.get(url2, headers=HEADERS)\n",
    "soup2 = BeautifulSoup(webpage2.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dropdowns = soup2.find_all(\"div\", class_='card-header')\n",
    "\n",
    "for i in main_dropdowns:\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_items_dict = {\n",
    "'Physiochemical Properties' : {'Molecular Weight':'', 'nRot':'', 'Heavy Atom Molecular Weight':'', 'nRig':'', 'Exact Molecular Weight':'', 'nRing':'', 'Solubility: LogS':'', 'nHRing':'', 'Solubility: LogP':'', 'No. of Aliphatic Rings':'', 'Acid Count':'', 'No. of Aromatic Rings':'', 'Base Count':'', 'No. of Aliphatic Carbocycles Rings':'', 'Atoms Count':'', 'No. of Aliphatic Hetero Cycles':'', 'No. of Heavy Atom':'', 'No. of Aromatic Carbocycles':'', 'nHetero':'', 'No. of Aromatic Hetero Cycles':'', 'nBridge Head':'', 'No. Saturated Carbocycles':'', 'No. of Hydrogen atom':'', 'No. of Saturated Hetero Cycles':'', 'No. of Carbon atom':'', 'No. of Saturated Rings':'', 'No. of Nitrogen atom':'', 'No. of Arom Atom':'', 'No. of Oxygen atom':'', 'No. of Arom Bond':'', 'nHA':'', 'APOL':'', 'nHD':'', 'BPOL':''},\n",
    "'Medicinal Chemistry Properties' : {'QED':'', 'Synth':'', 'Natural Product Likeliness':'', 'NR-PPAR-gamma':''},\n",
    "'Drug Likeliness' : {'Lipinski':'', 'Pfizer':'', 'GSK':'', 'Golden Triangle':''},\n",
    "'Absorption' : {'Pgp-inh':'', 'Pgp-sub':'', 'HIA':'', 'CACO-2':''},\n",
    "'Distribution' : {'MDCK':'', 'BBB':'', 'PPB':'', 'VDSS':''},\n",
    "'Metabolism' : {'FU':'', 'CYP1A2-inh':'', 'CYP1A2-sub':'', 'CYP2c19-inh':'', 'CYP2c19-sub':'', 'CYP2c9-inh':'', 'CYP2c9-sub':'', 'CYP2d6-inh':'', 'CYP2d6-sub':'', 'CYP3a4-inh':'', 'CYP3a4-sub':''},\n",
    "'Excretion' : {'CL':'', 'T12':''},\n",
    "'Toxicity' : {'hERG':'', 'Ames':'', 'ROA':'', 'SkinSen':'', 'Carcinogencity':'', 'EI':'', 'Respiratory':'', 'NR-Aromatase':''},\n",
    "'Antiviral Prediction' : {'Antiviral':'', 'Prediction':''}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "physicochemical_properties = ['Molecular Weight', 'nRot', 'Heavy Atom Molecular Weight', 'nRig', 'Exact Molecular Weight', 'nRing', 'Solubility: LogS', 'nHRing', 'Solubility: LogP', 'No. of Aliphatic Rings', 'Acid Count', 'No. of Aromatic Rings', 'Base Count', 'No. of Aliphatic Carbocycles Rings', 'Atoms Count', 'No. of Aliphatic Hetero Cycles', 'No. of Heavy Atom', 'No. of Aromatic Carbocycles', 'nHetero', 'No. of Aromatic Hetero Cycles', 'nBridge Head', 'No. Saturated Carbocycles', 'No. of Hydrogen atom', 'No. of Saturated Hetero Cycles', 'No. of Carbon atom', 'No. of Saturated Rings', 'No. of Nitrogen atom', 'No. of Arom Atom', 'No. of Oxygen atom', 'No. of Arom Bond', 'nHA', 'APOL', 'nHD', 'BPOL']\n",
    "medicinal_chemistry_properties = ['QED', 'Synth', 'Natural Product Likeliness', 'NR-PPAR-gamma']\n",
    "drug_likeliness = ['Lipinski', 'Pfizer', 'GSK', 'Golden Triangle']\n",
    "absorption = ['Pgp-inh', 'Pgp-sub', 'HIA', 'CACO-2']\n",
    "distribution = ['MDCK', 'BBB', 'PPB', 'VDSS']\n",
    "metabolism = ['FU', 'CYP1A2-inh', 'CYP1A2-sub', 'CYP2c19-inh', 'CYP2c19-sub', 'CYP2c9-inh', 'CYP2c9-sub', 'CYP2d6-inh', 'CYP2d6-sub', 'CYP3a4-inh', 'CYP3a4-sub']\n",
    "excretion = ['CL', 'T12']\n",
    "toxicity = ['hERG', 'Ames', 'ROA', 'SkinSen', 'Carcinogencity', 'EI', 'Respiratory', 'NR-Aromatase']\n",
    "antiviral_prediction = ['Antiviral', 'Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_details_to_dict(sub_header_lst):\n",
    "    k=0\n",
    "    for i in sub_header_lst:\n",
    "        if k % 2 == 0: # heading\n",
    "            heading = i.text.strip()\n",
    "        else:          # values\n",
    "            if heading in physicochemical_properties:\n",
    "                chemo_items_dict['Physiochemical Properties'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in medicinal_chemistry_properties:\n",
    "                chemo_items_dict['Medicinal Chemistry Properties'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in drug_likeliness:\n",
    "                chemo_items_dict['Drug Likeliness'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in absorption:\n",
    "                chemo_items_dict['Absorption'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in distribution:\n",
    "                chemo_items_dict['Distribution'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in metabolism:\n",
    "                chemo_items_dict['Metabolism'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in excretion:\n",
    "                chemo_items_dict['Excretion'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in toxicity:\n",
    "                chemo_items_dict['Toxicity'][heading] = str(i.text.strip())\n",
    "            \n",
    "            elif heading in antiviral_prediction:\n",
    "                chemo_items_dict['Antiviral Prediction'][heading] = str(i.text.strip())\n",
    "        k+=1\n",
    "    return chemo_items_dict\n",
    "\n",
    "\n",
    "def check_sub_headers(sub_header_html):\n",
    "    # sub_header_values_lst = []\n",
    "    \n",
    "    # j=0\n",
    "    # for i in sub_header_html:\n",
    "    #     if j%2 != 0:\n",
    "    #         sub_header_values_lst.append(i.text.strip())\n",
    "    #     j+=1\n",
    "    # print(len(sub_header_values_lst)) \n",
    "    # print(sub_header_values_lst) \n",
    "    if len(sub_header_html) == 0:\n",
    "        return \"No\" # no sub headers\n",
    "    else:\n",
    "        val_dict = add_details_to_dict(sub_header_html)\n",
    "        return (\"Yes\", val_dict) # sub_header_values_lst # pass to subsequent function\n",
    "\n",
    "# def get_website_html(plant_link):\n",
    "#     webpage = requests.get(plant_link, headers=HEADERS)\n",
    "#     soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "#     return soup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop_range = range(1494, len(df['Scientific Name']))\n",
    "# big_pause = 0\n",
    "\n",
    "# for i in tqdm((loop_range), desc=\"Processing\"):\n",
    "#     plant_name = df['Phytochemical'][i]\n",
    "#     plant_link = df['Link'][i]\n",
    "\n",
    "#     plant_website_html = get_website_html(plant_link) # getting HTML of plant details website\n",
    "#     per_plant_details = add_per_plant_details(plant_website_html, all_plant_info_dict) # collecting plant info to a dict\n",
    "#     all_plant_info_dict[plant_name] = per_plant_details # adding collected plant info to a main dict with plant sci name as key\n",
    "    \n",
    "#     big_pause += 1\n",
    "#     if big_pause % 50 == 0:\n",
    "#         time.sleep(2) # after continuous 50 runs, long break for server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='neist.res.in', port=443): Max retries exceeded with url: /osadhi/chemodetail.php?phyto=%0Adicerandrol+C (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7effb9960f40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/socket.py:966\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    965\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    967\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:1060\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7effb9960f40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:801\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    799\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 801\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py:594\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    596\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='neist.res.in', port=443): Max retries exceeded with url: /osadhi/chemodetail.php?phyto=%0Adicerandrol+C (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7effb9960f40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m url3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://neist.res.in/osadhi/chemodetail.php?phyto=+\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m281S\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C8\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m27R\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m29-6-methoxy-2-methylspiro\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5B3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C4-dihydroisoquinoline-1\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C7\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m27-6\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C8-dihydrocyclopenta\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5Bg\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5D\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5B1\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5Dbenzodioxole\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m5D-7\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C8\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m27-diol\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m url4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://neist.res.in/osadhi/chemodetail.php?phyto=\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m0AVitexin+2\u001b[39m\u001b[38;5;132;01m%27%\u001b[39;00m\u001b[38;5;124m27-O-beta-L-rhamnoside\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m webpage3 \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m soup3 \u001b[38;5;241m=\u001b[39m BeautifulSoup(webpage3\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# soup_man2 = BeautifulSoup(soup_man, \"html.parser\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# main_headers = soup_man2.find_all(\"div\", class_='card-header')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='neist.res.in', port=443): Max retries exceeded with url: /osadhi/chemodetail.php?phyto=%0Adicerandrol+C (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7effb9960f40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"
     ]
    }
   ],
   "source": [
    "url2 = \"https://neist.res.in/osadhi/chemodetail.php?phyto=%0Adicerandrol+C\"\n",
    "url3 = \"https://neist.res.in/osadhi/chemodetail.php?phyto=+%281S%2C8%27R%29-6-methoxy-2-methylspiro%5B3%2C4-dihydroisoquinoline-1%2C7%27-6%2C8-dihydrocyclopenta%5Bg%5D%5B1%2C3%5Dbenzodioxole%5D-7%2C8%27-diol\"\n",
    "url4 = \"https://neist.res.in/osadhi/chemodetail.php?phyto=%0AVitexin+2%27%27-O-beta-L-rhamnoside\"\n",
    "webpage3 = requests.get(url2, headers=HEADERS)\n",
    "soup3 = BeautifulSoup(webpage3.content, \"html.parser\")\n",
    "\n",
    "# soup_man2 = BeautifulSoup(soup_man, \"html.parser\")\n",
    "# main_headers = soup_man2.find_all(\"div\", class_='card-header')\n",
    "\n",
    "main_headers = soup3.find_all(\"div\", class_='card-header')\n",
    "\n",
    "if not main_headers: # No main headers like  Physiochemical Properties, Metabolism etc\n",
    "    print(\"main header - no\")\n",
    "elif main_headers: # Main headers present but no content in sub-headers\n",
    "    print(\"main header - yes\")\n",
    "    sub_headers = soup_man2.find_all(\"td\")\n",
    "    reply, sub_headers_with_values = check_sub_headers(sub_headers)\n",
    "    print(reply,\"\\n\", sub_headers_with_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup_man2.find_all(\"td\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup2.find(\"div\", class_='card-body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_info = soup2.find_all('td')\n",
    "\n",
    "j=0\n",
    "for i in inside_info:\n",
    "    if j%2 != 0:\n",
    "        chemo_values.append(i.text.strip())\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lst:\n",
    "    if i % 2 == 0: # heading\n",
    "        heading = i.text.strip()\n",
    "    else:          # values\n",
    "        if heading in physicochemical_properties:\n",
    "            chemo_items_dict['Physiochemical Properties'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in medicinal_chemistry_properties:\n",
    "            chemo_items_dict['Medicinal Chemistry Properties'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in drug_likeliness:\n",
    "            chemo_items_dict['Drug Likeliness'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in absorption:\n",
    "            chemo_items_dict['Absorption'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in distribution:\n",
    "            chemo_items_dict['Distribution'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in metabolism:\n",
    "            chemo_items_dict['Metabolism'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in excretion:\n",
    "            chemo_items_dict['Excretion'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in toxicity:\n",
    "            chemo_items_dict['Toxicity'][heading] = str(i.text.strip())\n",
    "        \n",
    "        elif heading in antiviral_prediction:\n",
    "            chemo_items_dict['Antiviral Prediction'][heading] = str(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plant_info_dict = {}\n",
    "\n",
    "def get_plant_website_html(plant_link):\n",
    "    plant_webpage = requests.get(plant_link, headers=HEADERS)\n",
    "    plant_soup = BeautifulSoup(plant_webpage.content, \"html.parser\")\n",
    "    return plant_soup\n",
    "\n",
    "def add_per_plant_details(soup, per_plant_details_dict):\n",
    "    per_plant_details_dict = {\n",
    "        'Summary': [],\n",
    "        'Statewise availability': [],\n",
    "        'Phytochemicals': [],\n",
    "        'Ailments cured': [],\n",
    "        'Plant parts and method of its use': [],\n",
    "        'Vernacular name': []\n",
    "        }\n",
    "    \n",
    "    for i in range(0, 6):\n",
    "        if i == 0:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Summary'].append(j.text)\n",
    "        if i == 1:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Statewise availability'].append(j.text)\n",
    "        if i == 2:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Phytochemicals'].append(j.text)\n",
    "        if i == 3:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Ailments cured'].append(j.text)\n",
    "        if i == 4:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Plant parts and method of its use'].append(j.text)\n",
    "        if i == 5:\n",
    "            for j in soup.table.find_all('ul')[i]:\n",
    "                per_plant_details_dict['Vernacular name'].append(j.text)\n",
    "\n",
    "    return per_plant_details_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OSADHI_Ethno_Scientific_Name_Links.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_range = range(1494, len(df['Scientific Name']))\n",
    "big_pause = 0\n",
    "\n",
    "for i in tqdm((loop_range), desc=\"Processing\"):\n",
    "    plant_name = df['Scientific Name'][i]\n",
    "    plant_link = df['Link'][i]\n",
    "\n",
    "    plant_website_html = get_plant_website_html(plant_link) # getting HTML of plant details website\n",
    "    per_plant_details = add_per_plant_details(plant_website_html, all_plant_info_dict) # collecting plant info to a dict\n",
    "    all_plant_info_dict[plant_name] = per_plant_details # adding collected plant info to a main dict with plant sci name as key\n",
    "    \n",
    "    big_pause += 1\n",
    "    if big_pause % 50 == 0:\n",
    "        time.sleep(2) # after continuous 50 runs, long break for server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"OSADHI_all_plant_details_json_file_NEW.json\", \"w\") as FinalOut: \n",
    "    json.dump(all_plant_info_dict, FinalOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "abc = None\n",
    "\n",
    "if abc:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OSADHI_all_plant_details_json_file_1.json') as f:\n",
    "    data1 = json.load(f)\n",
    "    \n",
    "with open('OSADHI_all_plant_details_json_file_NEW.json') as f: \n",
    "    data2 = json.load(f)\n",
    "\n",
    "data1.update(data2)\n",
    "\n",
    "with open('OSADHI_all_plant_details_json_file.json', 'w') as f:\n",
    "   json.dump(data1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OSADHI_all_plant_details_json_file.json') as f:\n",
    "    item_dict = json.load(f)\n",
    "\n",
    "len(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name_lst = df['Scientific Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, _ in item_dict.items():\n",
    "    try:\n",
    "        sci_name_lst.remove(key)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OSADHI_all_plants.json') as f:\n",
    "    item_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_dict's SUMMARY column DataFrame (df) \n",
    "\n",
    "first_entry = list(item_dict.values())[0]\n",
    "headers = [item.split(':')[0] for item in first_entry['Summary']]  # use first entry to get headers\n",
    "# headers expected output ['Scientific Name', 'Genus', 'Species', 'Family', 'Synonym']\n",
    "\n",
    "rows = []\n",
    "\n",
    "for plant_name, plant_data in item_dict.items():\n",
    "    summary = plant_data.get('Summary', []) # extracting Summary values\n",
    "    row = {}\n",
    "    for idx, header in enumerate(headers):\n",
    "        # Match summary items with corresponding headers\n",
    "        row[header] = summary[idx].split(':')[1] if idx < len(summary) else ''\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_dict's remaining column DataFrame (df1)\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(item_dict, orient='index')\n",
    "df1 = df1.map(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "df1.drop('Summary', axis=1, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging both dfs, df and df1\n",
    "\n",
    "merged_df = pd.concat([df.reset_index(drop=True), df1.reset_index(drop=True)], axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"OSADHI_ethno_all_plant_details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
